#!/usr/bin/env python3
"""
é‡æ–°åˆ†ç»„è¿ç§»è„šæœ¬
å°† leetcode_questions/ ä¸‹çš„28ä¸ª markdown æ–‡ä»¶æŒ‰æ¯4é¢˜ä¸€ç»„é‡æ–°ç”Ÿæˆ HTML
"""

import os
import json
import subprocess
from pathlib import Path
from datetime import datetime
from collections import defaultdict

try:
    import markdown2
    MARKDOWN2_AVAILABLE = True
except ImportError:
    MARKDOWN2_AVAILABLE = False
    print("âŒ markdown2 æœªå®‰è£…")
    print("è¯·å…ˆå®‰è£…: pip3 install markdown2")
    exit(1)


def scan_markdown_files(questions_dir):
    """æ‰«ææ‰€æœ‰ markdown æ–‡ä»¶å¹¶æŒ‰æ—¥æœŸåˆ†ç»„"""
    files_by_date = defaultdict(list)

    md_files = list(Path(questions_dir).glob("*.md"))
    print(f"å‘ç° {len(md_files)} ä¸ª markdown æ–‡ä»¶")

    for md_file in md_files:
        # ä»æ–‡ä»¶åæå–æ—¥æœŸï¼šé¢˜å·_éš¾åº¦_æ ‡é¢˜_æ—¥æœŸ.md
        filename = md_file.stem
        parts = filename.split('_')

        if len(parts) >= 4:
            date_str = parts[-1]  # æœ€åä¸€éƒ¨åˆ†æ˜¯æ—¥æœŸ
            if len(date_str) == 8 and date_str.isdigit():
                files_by_date[date_str].append(str(md_file))

    return files_by_date


def convert_group_to_html(md_files, date_str, time_str, group_num, docs_dir):
    """å°†ä¸€ç»„ markdown æ–‡ä»¶è½¬æ¢ä¸ºä¸€ä¸ª HTML æ–‡ä»¶"""
    if not md_files:
        return None

    # è¯»å–æ‰€æœ‰ markdown æ–‡ä»¶
    all_content = []
    for md_file in md_files:
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
                all_content.append(content)
        except Exception as e:
            print(f"  âš ï¸ è¯»å–å¤±è´¥ {md_file}: {e}")

    if not all_content:
        return None

    # åˆå¹¶å†…å®¹
    combined_md = "\n\n---\n\n".join(all_content)

    # è½¬æ¢ä¸º HTML
    html_body = markdown2.markdown(
        combined_md,
        extras=['fenced-code-blocks', 'tables', 'header-ids']
    )

    # ç”Ÿæˆ HTML æ–‡ä»¶
    formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
    formatted_time = f"{time_str[:2]}:{time_str[2:4]}:{time_str[4:]}"
    html_filename = f"{date_str}_{time_str}.html"
    html_file = docs_dir / html_filename

    full_html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LeetCode {formatted_date} {formatted_time}</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <div class="container">
        <a href="index.html" class="back-link">â† è¿”å›é¦–é¡µ</a>
        <div class="content">
            <h1>ğŸ“… {formatted_date} {formatted_time} æ¯æ—¥é¢˜ç›® (ç¬¬ {group_num} ç»„)</h1>
            {html_body}
        </div>
    </div>
</body>
</html>"""

    try:
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(full_html)
        return html_filename
    except Exception as e:
        print(f"  âœ— HTML ç”Ÿæˆå¤±è´¥: {e}")
        return None


def update_history_json(records, docs_dir):
    """æ›´æ–° history.json æ–‡ä»¶"""
    history_file = docs_dir / "history.json"

    try:
        # è¯»å–ç°æœ‰è®°å½•
        if history_file.exists():
            with open(history_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                existing_records = data.get('records', [])
        else:
            existing_records = []

        # åˆ é™¤æ—§çš„è¿ç§»è®°å½•ï¼ˆæ—¶é—´ä¸º 00:00:00 çš„è®°å½•ï¼‰
        filtered_records = [
            r for r in existing_records
            if not r['date'].endswith('00:00:00')
        ]

        # åˆå¹¶æ–°è®°å½•ï¼ˆæ–°è®°å½•åœ¨å‰ï¼‰
        all_records = records + filtered_records

        # å»é‡ï¼ˆåŸºäº file å­—æ®µï¼‰
        seen_files = set()
        unique_records = []
        for record in all_records:
            if record['file'] not in seen_files:
                seen_files.add(record['file'])
                unique_records.append(record)

        # æŒ‰æ—¥æœŸæ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        unique_records.sort(key=lambda x: x['date'], reverse=True)

        # ä¿å­˜
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump({
                'records': unique_records,
                'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }, f, ensure_ascii=False, indent=2)

        print(f"âœ“ å·²æ›´æ–° history.jsonï¼Œå…± {len(unique_records)} æ¡è®°å½•")
        return True

    except Exception as e:
        print(f"âœ— æ›´æ–° history.json å¤±è´¥: {e}")
        return False


def delete_old_migration_html(docs_dir):
    """åˆ é™¤æ—§çš„è¿ç§» HTML æ–‡ä»¶ï¼ˆ20260226_000000.htmlï¼‰"""
    old_file = docs_dir / "20260226_000000.html"
    if old_file.exists():
        try:
            old_file.unlink()
            print(f"âœ“ å·²åˆ é™¤æ—§æ–‡ä»¶: {old_file.name}")
            return True
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤æ—§æ–‡ä»¶å¤±è´¥: {e}")
            return False
    return True


def git_push(total_groups=0, total_questions=0):
    """æäº¤å¹¶æ¨é€åˆ° GitHub"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    if total_groups > 0:
        commit_message = f"ğŸ“‚ é‡æ–°åˆ†ç»„ | {total_groups} ç»„ Â· {total_questions} é“é¢˜ç›®\n\né‡ç»„æ—¶é—´: {timestamp}\næ¯ç»„: 4é¢˜\n\nğŸ¤– Regrouped by regroup_migration.py"
    else:
        commit_message = f"ğŸ“‚ é‡æ–°åˆ†ç»„\n\né‡ç»„æ—¶é—´: {timestamp}\n\nğŸ¤– Regrouped by regroup_migration.py"

    commands = [
        ['git', 'add', 'docs/'],
        ['git', 'commit', '-m', commit_message],
        ['git', 'push', 'origin', 'main']
    ]

    try:
        for cmd in commands:
            print(f"  æ‰§è¡Œ: {' '.join(cmd)}")
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode != 0:
                if 'nothing to commit' in result.stdout or 'nothing to commit' in result.stderr:
                    print(f"  â„¹ï¸  æ²¡æœ‰éœ€è¦æäº¤çš„å˜æ›´")
                    continue
                else:
                    print(f"  âœ— å‘½ä»¤å¤±è´¥: {result.stderr}")
                    return False

        print(f"âœ“ å·²æ¨é€åˆ° GitHub")
        return True

    except Exception as e:
        print(f"âœ— Git æ“ä½œå¤±è´¥: {e}")
        return False


def main():
    print("=" * 60)
    print("LeetCode é‡æ–°åˆ†ç»„è¿ç§»è„šæœ¬")
    print("å°†28é¢˜æŒ‰æ¯4é¢˜ä¸€ç»„é‡æ–°ç”Ÿæˆ HTML")
    print("=" * 60)
    print()

    # é…ç½®
    questions_dir = Path("leetcode_questions")
    docs_dir = Path("docs")

    if not questions_dir.exists():
        print("âŒ leetcode_questions ç›®å½•ä¸å­˜åœ¨")
        return

    docs_dir.mkdir(parents=True, exist_ok=True)

    # 1. æ‰«æç°æœ‰æ–‡ä»¶
    print("æ­¥éª¤ 1: æ‰«æç°æœ‰ markdown æ–‡ä»¶...")
    files_by_date = scan_markdown_files(questions_dir)

    if not files_by_date:
        print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦è¿ç§»çš„æ–‡ä»¶")
        return

    print(f"æ‰¾åˆ° {len(files_by_date)} ä¸ªä¸åŒæ—¥æœŸçš„æ–‡ä»¶")
    print()

    # 2. åˆ é™¤æ—§çš„è¿ç§»æ–‡ä»¶
    print("æ­¥éª¤ 2: åˆ é™¤æ—§çš„è¿ç§»æ–‡ä»¶...")
    delete_old_migration_html(docs_dir)
    print()

    # 3. æŒ‰4é¢˜ä¸€ç»„è½¬æ¢ä¸º HTML
    print("æ­¥éª¤ 3: æŒ‰4é¢˜ä¸€ç»„è½¬æ¢ä¸º HTML...")
    new_records = []

    # æŒ‰æ—¥æœŸæ’åºï¼ˆä»æ—§åˆ°æ–°ï¼‰
    sorted_dates = sorted(files_by_date.keys())

    for date_str in sorted_dates:
        md_files = sorted(files_by_date[date_str])  # æ’åºä¿è¯é¡ºåºä¸€è‡´
        formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"

        print(f"\nå¤„ç† {formatted_date} ({len(md_files)} ä¸ªæ–‡ä»¶)")

        # æ¯4ä¸ªæ–‡ä»¶ä¸€ç»„
        group_size = 4
        total_groups = (len(md_files) + group_size - 1) // group_size

        for i in range(0, len(md_files), group_size):
            group_files = md_files[i:i+group_size]
            group_num = i // group_size + 1

            # ä¸ºæ¯ç»„ç”Ÿæˆä¸åŒçš„æ—¶é—´æˆ³ï¼ˆæ¯ç»„é—´éš”1å°æ—¶ï¼‰
            hour = i // group_size
            time_str = f"{hour:02d}0000"  # 00:00:00, 01:00:00, 02:00:00...

            html_filename = convert_group_to_html(
                group_files,
                date_str,
                time_str,
                group_num,
                docs_dir
            )

            if html_filename:
                formatted_time = f"{time_str[:2]}:{time_str[2:4]}:{time_str[4:]}"
                print(f"  âœ“ ç¬¬ {group_num}/{total_groups} ç»„: {html_filename} ({len(group_files)} é¢˜)")

                # æ·»åŠ åˆ°è®°å½•
                new_records.append({
                    'date': f"{formatted_date} {formatted_time}",
                    'file': html_filename,
                    'count': len(group_files)
                })
            else:
                print(f"  âœ— ç¬¬ {group_num} ç»„ç”Ÿæˆå¤±è´¥")

    print()
    print(f"æˆåŠŸè½¬æ¢ {len(new_records)} ç»„æ–‡ä»¶")
    print()

    # 4. æ›´æ–° history.json
    print("æ­¥éª¤ 4: æ›´æ–° history.json...")
    update_history_json(new_records, docs_dir)
    print()

    # 5. æ¨é€åˆ° GitHub
    print("æ­¥éª¤ 5: æ¨é€åˆ° GitHub...")

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_questions = sum(r['count'] for r in new_records)

    # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº† GitHub Pages
    try:
        with open('config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
            github_enabled = config.get('github_pages', {}).get('enabled', False)
    except:
        github_enabled = False

    if github_enabled:
        git_push(len(new_records), total_questions)
    else:
        print("  âš ï¸  GitHub Pages æœªå¯ç”¨ï¼Œè·³è¿‡æ¨é€")
        print("  æç¤º: å¦‚éœ€æ¨é€ï¼Œè¯·åœ¨ config.json ä¸­å¯ç”¨ github_pages")

    print()
    print("=" * 60)
    print("é‡æ–°åˆ†ç»„å®Œæˆï¼")
    print("=" * 60)
    print()
    print("ç”Ÿæˆçš„æ–‡ä»¶:")
    for record in new_records:
        print(f"  â€¢ {record['date']} - {record['file']} ({record['count']} é¢˜)")
    print()
    print("ä½ å¯ä»¥æ‰“å¼€ docs/index.html æŸ¥çœ‹æ•ˆæœ")
    print()


if __name__ == "__main__":
    main()
